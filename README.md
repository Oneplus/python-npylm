# NPYLM

[ベイズ階層言語モデルによる教師なし形態素解析](http://chasen.org/~daiti-m/paper/nl190segment.pdf)のC++実装です。

単語n-gramモデルは3-gramで固定です。2-gramは非対応です。

現在も開発途中です。

## 動作環境

- Boost

## ビルド

```
make install
```

## 実行

```
python train.py -f textfile.txt -l 16
```

### オプション

- -f
	- 学習に使うテキストファイル
- -i
	- 学習に使うテキストファイル群が入っているディレクトリ
	- 複数ファイルを用いる場合はこちらを指定
- t
	- 読み込んだ行のうち何割を学習に用いるか
	- 0から1の実数を指定
	- 1を指定すると全データを用いてモデルを学習する
- l
	- 可能な単語の最大長
	- 日本語なら12〜16、英語なら20程度を指定
	- 分の長さをN、単語の最大長をLとすると、NPYLMの計算量はO(NL^2)になる

## 単語分割

```
python viterbi.py -f textfile.txt
```

### オプション

- -f
	- 分割するテキストファイル
- -i
	- 分割するテキストファイル群が入っているディレクトリ
	- 複数ファイルをまとめて分割する場合はこちらを指定
	- ファイルごとに個別の出力ファイルが作成されます

## 注意事項

研究以外の用途には使用できません。

https://twitter.com/daiti_m/status/851810748263157760

## 展望

現在、[条件付確率場とベイズ階層言語モデルの統合による半教師あり形態素解析](http://chasen.org/~daiti-m/paper/nlp2011semiseg.pdf)を実装しています。

完成次第公開します。